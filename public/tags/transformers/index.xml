<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Transformers on Damilola John</title>
    <link>damilojohn.github.io/tags/transformers/</link>
    <description>Recent content in Transformers on Damilola John</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright Damilola John &amp;copy; 2023</copyright>
    <lastBuildDate>Fri, 11 Aug 2023 02:14:46 +0100</lastBuildDate><atom:link href="damilojohn.github.io/tags/transformers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Playlist Generator</title>
      <link>damilojohn.github.io/projects/playlist_generator/</link>
      <pubDate>Fri, 11 Aug 2023 02:14:46 +0100</pubDate>
      
      <guid>damilojohn.github.io/projects/playlist_generator/</guid>
      <description>Playlist Generator An app that uses semantic search to generate afrobeat song playlists from input texts In the last year , ChatGPT changed the landscape of Artificial Intelligence and software engineering.
This is why I and emmanuel offisong decided to build an app that made it easier to discover new afrobeats songs</description>
    </item>
    
    <item>
      <title>Byte-Pair Encoding, The Tokenization algorithm powering Large LanguageÂ Models. </title>
      <link>damilojohn.github.io/posts/bpe/</link>
      <pubDate>Thu, 10 Aug 2023 04:14:46 +0100</pubDate>
      
      <guid>damilojohn.github.io/posts/bpe/</guid>
      <description>Tokenization is an umbrella term for the methods used to turn texts into chunks of words or sub-words. Tokenization has a lot of applications in computer science, from compilers to Natural Language Processing. In this article, we would be focusing on tokenizers in Language models, in particular, a method of tokenization called Byte Pair Encoding. The last few years have witnessed a revolution in NLP catalyzed mainly by the introduction of the transformers architecture in 2017 with the paper &amp;lsquo;Attention is all you need &amp;rsquo; epitomized by the introduction of ChatGPT in late 2022.</description>
    </item>
    
    <item>
      <title>I Tried to teach BERT 15 programming languages. </title>
      <link>damilojohn.github.io/posts/language_classification/</link>
      <pubDate>Thu, 10 Aug 2023 04:14:46 +0100</pubDate>
      
      <guid>damilojohn.github.io/posts/language_classification/</guid>
      <description>This is was a fun side project where I decided to build a model that could tell 15 of the most popular programming languages apart We would start with simple machine learning approaches and work our way up to more complex methods till we have a satisfactory solution.
The Dataset Our dataset is a csv containing 45,000 samples . The dataset is made up of two columns, the &amp;lsquo;code&amp;rsquo; feature contains code snippets we want to classify and the language column, which is our label contains the programming language it belongs to.</description>
    </item>
    
  </channel>
</rss>
